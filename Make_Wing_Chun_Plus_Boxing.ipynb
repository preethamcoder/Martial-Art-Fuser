{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f35260bb-c313-42fc-b687-c7d5f61ae5a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m      4\u001b[0m img_height, img_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "img_height, img_width = 64, 64\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    'tai_chi/',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec1de8-4966-4209-90a6-75405933d7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_generator(z_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, input_dim=z_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.5))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.5))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(1024))\n",
    "    model.add(layers.LeakyReLU(alpha=0.5))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Dense(img_height * img_width * 3, activation='tanh'))\n",
    "    model.add(layers.Reshape((img_height, img_width, 3)))\n",
    "    return model\n",
    "\n",
    "z_dim = 100  # Size of the noise vector\n",
    "generator = build_generator(z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4d09c-3bfe-453e-9659-baeb95a189a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=img_shape))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.4))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.4))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator((img_height, img_width, 3))\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fccfb9-51a6-480e-a72d-4152261f8c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    model = models.Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "discriminator.trainable = True\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fd7d0-77f7-47ca-a890-9fe33de8cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_images(generator, epoch, z_dim, examples=32):\n",
    "    noise = np.random.normal(0, 1, size=(examples, z_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale from [-1, 1] to [0, 1]\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory = f'fin/_epoch_{epoch}/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save each image separately\n",
    "    for ind, img in enumerate(generated_images):\n",
    "        plt.figure()\n",
    "        plt.imshow(img, interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f'{directory}_{epoch}_image_{ind}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8bf4b-70be-4d8a-b998-90b6b5bb95fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "losses = []\n",
    "def train_gan(generator, discriminator, gan, dataset, z_dim, epochs=100):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Train Discriminator with real images\n",
    "        if epoch % 2 == 0:\n",
    "            real = dataset.next()\n",
    "            real = real * 2.0 - 1.0\n",
    "            real_labels = np.ones((real.shape[0], 1))*0.65\n",
    "            d_loss_real = discriminator.train_on_batch(real, real_labels)\n",
    "\n",
    "        # Train Discriminator with fake images\n",
    "        # if epoch % 2 == 0:\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        fake = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))+0.35\n",
    "        d_loss_fake = discriminator.train_on_batch(fake, fake_labels)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "        valid_y = np.array([1] * batch_size)\n",
    "        g_loss = gan.train_on_batch(noise, valid_y)\n",
    "        # Print progress\n",
    "        if epoch % 10 == 0:\n",
    "            losses.append(f\"Epoch: {epoch} D_loss_real: {d_loss_real[0]} D_loss_fake: {d_loss_fake[0]} G_loss: {g_loss}\")\n",
    "            #save_images(generator, epoch, z_dim)\n",
    "\n",
    "train_gan(generator, discriminator, gan, train_data, z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e370d54-5ce3-4387-967c-0e77d33054e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
